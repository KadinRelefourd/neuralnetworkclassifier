{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KadinRelefourd/neuralnetworkclassifier/blob/main/classifyFINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZLVcLoW9zD1"
      },
      "source": [
        "colab inviornment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LYtPEdnm97i_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW7iqcpe78L1"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Vqlwu1Uu535l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2  # OpenCV for image processing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVW_Z6a-Gby"
      },
      "source": [
        "Prepare Training and Testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YA3Ueyp-LAy",
        "outputId": "97831000-00db-4972-da5a-900543b12a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data.cifar10',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data.cifar10',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaw4gBlL-MrO"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nmtGhK8Q-Tvd"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 512)  # Input size: CIFAR-10 images are 32x32x3\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "        self.fc5 = nn.Linear(64, 10)  # Output size: 10 classes (CIFAR-10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input image\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.dropout(x, p=0.3)  # Apply dropout for regularization\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = F.dropout(x, p=0.3)\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        x = F.dropout(x, p = 0.3)\n",
        "        x = F.relu(self.bn4(self.fc4(x)))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "loss_func = nn.CrossEntropyLoss()  # CrossEntropyLoss includes softmax internally\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfJg-NnS-WC4"
      },
      "source": [
        "Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "s7sAIYwp-a55"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()  # Switch the model to evaluation mode (disables dropout, batch norm updates)\n",
        "    correct = 0  # Initialize a counter for correctly predicted samples\n",
        "    total = 0  # Initialize a counter for the total number of samples\n",
        "    total_loss = 0.0  # Initialize a variable to accumulate the total loss\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation (saves memory and speeds up inference)\n",
        "        for inputs, targets in test_loader:  # Iterate through the test dataset\n",
        "            outputs = model(inputs)  # Forward pass: get predictions from the model\n",
        "            loss = loss_func(outputs, targets)  # Compute the loss for the batch\n",
        "            total_loss += loss.item()  # Accumulate the total loss\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class (highest probability)\n",
        "            total += targets.size(0)  # Update the total number of samples processed\n",
        "            correct += (predicted == targets).sum().item()  # Count correctly predicted samples\n",
        "\n",
        "    accuracy = 100 * correct / total  # Compute the accuracy percentage\n",
        "    return total_loss / len(test_loader), accuracy  # Return the average loss and accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1gHEGEgDmSd"
      },
      "source": [
        "Training Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WA91tfWGDr2v"
      },
      "outputs": [],
      "source": [
        "def train_accuracy():\n",
        "    model.eval()  # Switch to evaluation mode for accuracy calculation on training data\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in train_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuxnBZYZ-pLb"
      },
      "source": [
        "Save Model function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ygU-J95x-zU8"
      },
      "outputs": [],
      "source": [
        "def save_model(epoch):\n",
        "    if not os.path.exists('./model'):\n",
        "        os.makedirs('./model')\n",
        "    torch.save(model.state_dict(), './model/model.ckpt')  # Save with fixed filename\n",
        "    print(f\"Model saved in file: ./model/model.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjFxIcLZ-3Zs"
      },
      "source": [
        "Load Model Funciont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WZn7rdkC-7Qt"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxTosHPZ-_PF"
      },
      "source": [
        "Train Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HQtCdVJC_Jxv"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    print(f\"{'Loop':<8}{'Train Loss':<15}{'Train Acc %':<15}{'Test Loss':<15}{'Test Acc %':<15}\")\n",
        "\n",
        "    last_train_acc = 0  # Track the last training accuracy\n",
        "\n",
        "    for epoch in range(10):  # Train for 10 epochs\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Evaluate after each epoch\n",
        "        train_acc = train_accuracy()\n",
        "        test_loss, test_accuracy = test()\n",
        "\n",
        "        # Ensure training accuracy only goes up\n",
        "        if train_acc < last_train_acc:\n",
        "         last_train_acc = train_acc  # Update last training accuracy\n",
        "\n",
        "        #this\n",
        "        print(f\"{epoch + 1}/10   {total_loss / len(train_loader):<15.4f}{train_acc:<15.2f}{test_loss:<15.4f}{test_accuracy:<15.2f}\")\n",
        "\n",
        "        # Save the model only after the last epoch (10th epoch)\n",
        "        if epoch == 9:\n",
        "            save_model(epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5xReWaR_NNx"
      },
      "source": [
        "Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "U7OcjPEm_U7d"
      },
      "outputs": [],
      "source": [
        "def classify(image_path):\n",
        "    load_model('./model/model.ckpt')  # Load the best model from training\n",
        "    model.eval()\n",
        "\n",
        "    # Read the image using OpenCV and preprocess it\n",
        "    img = cv2.imread(image_path)  # Load image as a NumPy array (BGR format)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error: Image not found or invalid path.\")\n",
        "        return\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB format (CIFAR-10 uses RGB)\n",
        "    img_resized = cv2.resize(img, (32, 32))  # Resize to CIFAR-10 dimensions (32x32)\n",
        "\n",
        "    img_tensor = transform(img_resized).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        _, predicted_class = torch.max(output.data, 1)\n",
        "\n",
        "    classes = train_data.classes\n",
        "    print(f'Prediction result: {classes[predicted_class.item()]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu_4nh7o_b7S"
      },
      "source": [
        "Command Line prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vA1MWw0x_a-9"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    command = sys.argv[1]\n",
        "\n",
        "    if command == \"train\":\n",
        "        train()\n",
        "\n",
        "    elif command == \"test\":\n",
        "        image_path = sys.argv[2]\n",
        "        classify(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Save a test image from CIFAR-10's test dataset\n",
        "img, label = test_data[0]  # First test image\n",
        "classes = test_data.classes  # Class names\n",
        "\n",
        "# Convert tensor to NumPy array (HWC format)\n",
        "img_np = img.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Create a folder to store the image\n",
        "if not os.path.exists('./test_images'):\n",
        "    os.makedirs('./test_images')\n",
        "\n",
        "# Save the image\n",
        "plt.imsave(f'./test_images/test_img_0_{classes[label]}.png', img_np)\n",
        "print(f\"Saved: ./test_images/test_img_0_{classes[label]}.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FewT3LR5U_PH",
        "outputId": "953d1c42-7246-469a-a62a-6b071dcfeec0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: ./test_images/test_img_0_cat.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify.py test ./test_images/test_img_0_cat.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEdn4BheVGPl",
        "outputId": "c2613953-cc16-4c2c-8e4f-22ed0eb3dd89"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/content/classify.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/classify.py\", line 201, in <module>\n",
            "    classify(image_path)\n",
            "  File \"/content/classify.py\", line 167, in classify\n",
            "    load_model('./model/model_epoch_9.pt')  # Load the best model from training\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/classify.py\", line 125, in load_model\n",
            "    model.load_state_dict(torch.load(model_path))\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './model/model_epoch_9.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GGMmiO1AQG5"
      },
      "source": [
        "Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0sq0hq5AZr2",
        "outputId": "82298e94-5da7-4520-8670-ad4a14d18f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Loop    Train Loss     Train Acc %    Test Loss      Test Acc %     \n",
            "1/10   1.9490         37.50          1.7693         37.18          \n",
            "2/10   1.7101         40.98          1.6718         40.34          \n",
            "3/10   1.6259         44.14          1.5919         42.93          \n",
            "4/10   1.5696         44.87          1.5788         43.37          \n",
            "5/10   1.5227         46.82          1.5428         44.41          \n",
            "6/10   1.4910         47.16          1.5492         44.42          \n",
            "7/10   1.4598         48.08          1.5271         45.63          \n",
            "8/10   1.4347         49.91          1.4901         47.01          \n",
            "9/10   1.4086         48.92          1.5360         45.12          \n",
            "10/10   1.3924         52.08          1.4617         47.79          \n",
            "Model saved in file: ./model/model.ckpt\n"
          ]
        }
      ],
      "source": [
        "!python classify.py train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K6epvE1AYoZ"
      },
      "source": [
        "train"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMCFCh8A3k9VMWqgFWuBOaE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}